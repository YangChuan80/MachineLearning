{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow import keras\n",
    "\n",
    "from os import walk\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pathBase = 'I://Chuan//Documents//MyData//ProjNormalCAG//CoroBase//Arrangement//'\n",
    "pathBase = 'E://Chuan//Documents//Database//DICOM//CoroBase//Arrangement//'\n",
    "\n",
    "theWhole = {}\n",
    "# theWhole is dictionary containing views (keys) which the values are DICOM files\n",
    "\n",
    "f = []\n",
    "f_LCA_Caudal = []\n",
    "mypath_LCA_Caudal = pathBase + 'LCA_Caudal'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_LCA_Caudal):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_LCA_Caudal.append(mypath_LCA_Caudal + '\\\\' + l) \n",
    "    \n",
    "f = []\n",
    "f_LCA_Cranial = []\n",
    "mypath_LCA_Cranial = pathBase + 'LCA_Cranial'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_LCA_Cranial):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_LCA_Cranial.append(mypath_LCA_Cranial + '\\\\' + l) \n",
    "    \n",
    "f = []\n",
    "f_LCA_Cranial_LAO = []\n",
    "mypath_LCA_Cranial_LAO = pathBase + 'LCA_Cranial_LAO'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_LCA_Cranial_LAO):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_LCA_Cranial_LAO.append(mypath_LCA_Cranial_LAO + '\\\\' + l) \n",
    "    \n",
    "    \n",
    "f = []\n",
    "f_LCA_Cranial_RAO = []\n",
    "mypath_LCA_Cranial_RAO = pathBase + 'LCA_Cranial_RAO'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_LCA_Cranial_RAO):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_LCA_Cranial_RAO.append(mypath_LCA_Cranial_RAO + '\\\\' + l) \n",
    "    \n",
    "f = []\n",
    "f_LCA_Spider = []\n",
    "mypath_LCA_Spider = pathBase + 'LCA_Spider'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_LCA_Spider):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_LCA_Spider.append(mypath_LCA_Spider + '\\\\' + l) \n",
    "    \n",
    "f = []\n",
    "f_RCA_Cranial = []\n",
    "mypath_RCA_Cranial = pathBase + 'RCA_Cranial'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_RCA_Cranial):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_RCA_Cranial.append(mypath_RCA_Cranial + '\\\\' + l) \n",
    "    \n",
    "f = []\n",
    "f_RCA_LAO = []\n",
    "mypath_RCA_LAO = pathBase + 'RCA_LAO'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_RCA_LAO):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_RCA_LAO.append(mypath_RCA_LAO + '\\\\' + l) \n",
    "    \n",
    "\n",
    "theWhole['LCA_Caudal'] = f_LCA_Caudal\n",
    "theWhole['LCA_Cranial'] = f_LCA_Cranial\n",
    "theWhole['LCA_Cranial_LAO'] = f_LCA_Cranial_LAO\n",
    "theWhole['LCA_Cranial_RAO'] = f_LCA_Cranial_RAO\n",
    "theWhole['LCA_Spider'] = f_LCA_Spider\n",
    "theWhole['RCA_Cranial'] = f_RCA_Cranial\n",
    "theWhole['RCA_LAO'] = f_RCA_LAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewConvert = {'LCA_Caudal': 0, \n",
    "               'LCA_Cranial': 1,\n",
    "               'LCA_Cranial_LAO': 2,\n",
    "               'LCA_Cranial_RAO': 3,\n",
    "               'LCA_Spider': 4,\n",
    "               'RCA_Cranial': 5,\n",
    "               'RCA_LAO': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theWhole['LCA_Cranial_LAO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = {}\n",
    "i = 0\n",
    "\n",
    "for view in theWhole.keys():\n",
    "    array[view] = []\n",
    "    for case in theWhole[view]:\n",
    "        if case.split('.')[-1] == 'npy':\n",
    "            arr = np.load(case)\n",
    "            array[view].append(arr)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample_list = []\n",
    "y_sample_list = []\n",
    "\n",
    "for y, x in array.items():    \n",
    "    for x_item in x:\n",
    "        x_sample_list.append(x_item)\n",
    "        y_sample_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(x_sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_sample_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample_digital_list = []\n",
    "for item in y_sample_list:\n",
    "    y_sample_digital_list.append(viewConvert[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(x_sample_list).reshape(-1, 512, 512, 1)\n",
    "y_train = np.array(y_sample_digital_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathBase = 'I://Chuan//Documents//MyData//ProjNormalCAG//CoroBase//Arrangement//test//'\n",
    "#pathBase = 'I://Chuan//Documents//MyData//NormalCAG//CoroBase//Arrangement//test//'\n",
    "#pathBase = 'E://Chuan//Documents//Database//DICOM//CoroBase//Arrangement//test//'\n",
    "\n",
    "theWhole = {}\n",
    "\n",
    "f = []\n",
    "f_LCA_Caudal = []\n",
    "mypath_LCA_Caudal = pathBase + 'LCA_Caudal'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_LCA_Caudal):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_LCA_Caudal.append(mypath_LCA_Caudal + '\\\\' + l) \n",
    "    \n",
    "f = []\n",
    "f_LCA_Cranial = []\n",
    "mypath_LCA_Cranial = pathBase + 'LCA_Cranial'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_LCA_Cranial):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_LCA_Cranial.append(mypath_LCA_Cranial + '\\\\' + l) \n",
    "    \n",
    "f = []\n",
    "f_LCA_Cranial_LAO = []\n",
    "mypath_LCA_Cranial_LAO = pathBase + 'LCA_Cranial_LAO'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_LCA_Cranial_LAO):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_LCA_Cranial_LAO.append(mypath_LCA_Cranial_LAO + '\\\\' + l) \n",
    "    \n",
    "    \n",
    "f = []\n",
    "f_LCA_Cranial_RAO = []\n",
    "mypath_LCA_Cranial_RAO = pathBase + 'LCA_Cranial_RAO'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_LCA_Cranial_RAO):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_LCA_Cranial_RAO.append(mypath_LCA_Cranial_RAO + '\\\\' + l) \n",
    "    \n",
    "f = []\n",
    "f_LCA_Spider = []\n",
    "mypath_LCA_Spider = pathBase + 'LCA_Spider'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_LCA_Spider):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_LCA_Spider.append(mypath_LCA_Spider + '\\\\' + l) \n",
    "    \n",
    "f = []\n",
    "f_RCA_Cranial = []\n",
    "mypath_RCA_Cranial = pathBase + 'RCA_Cranial'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_RCA_Cranial):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_RCA_Cranial.append(mypath_RCA_Cranial + '\\\\' + l) \n",
    "    \n",
    "f = []\n",
    "f_RCA_LAO = []\n",
    "mypath_RCA_LAO = pathBase + 'RCA_LAO'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_RCA_LAO):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_RCA_LAO.append(mypath_RCA_LAO + '\\\\' + l) \n",
    "    \n",
    "\n",
    "theWhole['LCA_Caudal'] = f_LCA_Caudal\n",
    "theWhole['LCA_Cranial'] = f_LCA_Cranial\n",
    "theWhole['LCA_Cranial_LAO'] = f_LCA_Cranial_LAO\n",
    "theWhole['LCA_Cranial_RAO'] = f_LCA_Cranial_RAO\n",
    "theWhole['LCA_Spider'] = f_LCA_Spider\n",
    "theWhole['RCA_Cranial'] = f_RCA_Cranial\n",
    "theWhole['RCA_LAO'] = f_RCA_LAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = {}\n",
    "i = 0\n",
    "\n",
    "for view in theWhole.keys():\n",
    "    array[view] = []\n",
    "    for case in theWhole[view]:\n",
    "        if case.split('.')[-1] == 'npy':\n",
    "            arr = np.load(case)\n",
    "            array[view].append(arr)\n",
    "\n",
    "x_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for y, x in array.items():    \n",
    "    for x_item in x:\n",
    "        x_test_list.append(x_item)\n",
    "        y_test_list.append(y)\n",
    "        \n",
    "y_test_digital_list = []\n",
    "for item in y_test_list:\n",
    "    y_test_digital_list.append(viewConvert[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(x_test_list).reshape(-1, 512, 512, 1)\n",
    "y_test = np.array(y_test_digital_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train', X_train)\n",
    "np.save('y_train', y_train)\n",
    "\n",
    "np.save('X_test', X_test)\n",
    "np.save('y_test', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "\n",
    "X_test = np.load('X_test.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(512, 512, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard Initilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=64, verbose=1, \n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9037.644499540329/3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('coroLearning_NeralNetwork1') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.models.load_model('coroLearning_NeralNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_predict = clf.predict(X_test)\n",
    "#y_test = y_test\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_filtered = []\n",
    "for sample in y_predict:\n",
    "    for i in range(7):\n",
    "        if sample[i] > 0.5:\n",
    "            y_predict_filtered.append(i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix (混淆矩阵)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = np.array(confusion_matrix(y_test, y_predict_filtered, labels=[0, 1, 2, 3, 4, 5, 6]))\n",
    "confusion = pd.DataFrame(cm, index=[0, 1, 2, 3, 4, 5, 6],\n",
    "                        columns=[0, 1, 2, 3, 4, 5, 6])\n",
    "confusion.to_csv('ConfusionMatrix_NN.csv')\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predict_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "heat_map = sb.heatmap(confusion, annot=True, \n",
    "                      cmap='coolwarm', \n",
    "                      xticklabels=confusion.columns, yticklabels=confusion.index, \n",
    "                      linewidths=.5, \n",
    "                      annot_kws={\"size\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map.figure.savefig(\"Heatmap_SVM.png\", dpi=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

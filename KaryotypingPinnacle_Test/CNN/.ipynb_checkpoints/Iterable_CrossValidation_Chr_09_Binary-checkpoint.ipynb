{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "slIdjqTJhM8B"
   },
   "source": [
    "# Facilitated Machine Learning Models for Karyotyping in the Patients with Chromosomal Abnormalities: Retrospective Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chr 09 vs Chr 09 Inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xrnbxOZChM8E"
   },
   "source": [
    "# 0. Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aKjA8v4hhM8E"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow import keras\n",
    "\n",
    "from os import walk\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KFSsnYohM8H"
   },
   "source": [
    "# 1. Samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Chormosome Label Convert by using Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromConvert = {\n",
    "               'chr_09': 0, \n",
    "               'chr_9_inversion': 1\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromConvert_reverse = {\n",
    "                0: 'chr_09',\n",
    "                1: 'chr_9_inversion'\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. File Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Filename Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YcabYh2hM8I"
   },
   "outputs": [],
   "source": [
    "# pathBase = 'C:\\\\Users\\\\Chuan\\\\OneDrive\\\\Dowrun\\\\Database\\\\PhD\\\\KaryoTypes\\\\Arrangement\\\\'\n",
    "# pathBase = 'I:\\\\Chuan\\\\Documents\\\\MyData\\\\PhD\\\\Karyotype\\\\Arrangement\\\\'\n",
    "# pathBase = 'D:\\\\Users\\\\Chuan\\\\Documents\\\\Database\\\\Karyotypes\\\\Arrangement\\\\'\n",
    "# ///////////////////////////////////////////////\n",
    "# Merged Database\n",
    "#pathBase = 'D:\\\\Users\\\\Chuan\\\\Documents\\\\Database\\\\Karyotypes\\\\Arrangement_Merged\\\\'\n",
    "\n",
    "pathBase = 'I:\\\\Chuan\\\\Documents\\\\MyData\\\\PhD\\\\Karyotype\\\\Arrangement_Merged\\\\'\n",
    "\n",
    "theWhole = {}\n",
    "        \n",
    "f = []\n",
    "f_09 = []\n",
    "mypath_09 = pathBase + 'chr_09'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_09):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_09.append(mypath_09 + '\\\\' + l)    \n",
    "    \n",
    "# ///////// Abnormal ones //////////////\n",
    "\n",
    "f = []\n",
    "f_9_inversion = []\n",
    "mypath_9_inversion = pathBase + 'chr_9_inversion'\n",
    "for (dirpath, dirnames, filenames) in walk(mypath_9_inversion):\n",
    "    f.extend(filenames)\n",
    "for l in f:\n",
    "    f_9_inversion.append(mypath_9_inversion + '\\\\' + l)  \n",
    "    \n",
    "theWhole['chr_09'] = f_09\n",
    "theWhole['chr_9_inversion'] = f_9_inversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6d8Ej2MShM8K",
    "outputId": "da32c938-49bb-4cec-9ded-708887ff9d05",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theWhole['chr_9_inversion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(theWhole['chr_09'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(theWhole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(theWhole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theWhole.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractData(image):\n",
    "    x = image.size[0]\n",
    "    y = image.size[1]\n",
    "    \n",
    "    matrix = []\n",
    "    rgb_matrix = []\n",
    "\n",
    "    for i in range(x):\n",
    "        matrix.append([])\n",
    "        rgb_matrix.append([])\n",
    "        \n",
    "        for j in range(y):\n",
    "            r, g, b = image.getpixel((j, i))            \n",
    "            value = r * 299.0/1000 + g * 587.0/1000 + b * 114.0/1000\n",
    "            value = int(value)\n",
    "            matrix[i].append(value)\n",
    "            rgb_matrix[i].append((r,g,b))\n",
    "    return matrix, rgb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageReconstruct(matrix):\n",
    "    df = np.array(matrix, dtype=np.uint8)\n",
    "    img = Image.fromarray(df, 'RGB')\n",
    "    img.save('image.png')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Let's say split every class into 7 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "\n",
    "kfold = KFold(k, True, 1)\n",
    "\n",
    "# 分成7个子集，每次6个子集用于训练，1个子集用于测试\n",
    "# 每种分法进行一次训练和测试的迭代，总共8次迭代。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Assignment of filename which has been splitted randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_name = {}\n",
    "X_test_name = {}\n",
    "\n",
    "# 赋值两个接收文件路径的dictionary，其第一个key值为染色体或异常核型的名称，第二个为交叉验证（迭代）的序号\n",
    "\n",
    "for chrNo in theWhole.keys():\n",
    "\n",
    "    X_train_name[chrNo] = {}\n",
    "    X_test_name[chrNo] = {}\n",
    "    \n",
    "    # chrNo为染色体号或异常核型号，在此内部再定义迭代次数\n",
    "\n",
    "    split_method_number = 0\n",
    "    \n",
    "    # 赋值每次split分法的序号值\n",
    "\n",
    "    generator_kFold = kfold.split(theWhole[chrNo])\n",
    "    \n",
    "    # 依染色体或异常核型的类型进行split，因为每个类别的样本量不均衡，以每个类别进行split\n",
    "    # 赋值一个generator对象，以下对generator进行迭代。\n",
    "    \n",
    "    print('Chromosome/Abnormality: ', chrNo)\n",
    "\n",
    "    for train, test in generator_kFold:    \n",
    "        \n",
    "        # 循环产生train和test集\n",
    "\n",
    "        print('Split Method No. ', split_method_number)\n",
    "\n",
    "        print('Train: ', train, 'Test: ', test, '\\n')\n",
    "\n",
    "        # train和test的值是7个split分法的每个分法的list\n",
    "\n",
    "        X_train_name[chrNo][split_method_number] = []\n",
    "        X_test_name[chrNo][split_method_number] = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for split_method_train in train:\n",
    "            \n",
    "            # train 为训练集list中的序号值\n",
    "\n",
    "            # split_method_train的值是每个split方法，其值为图像序号\n",
    "            \n",
    "            X_train_name[chrNo][split_method_number].append(theWhole[chrNo][split_method_train])\n",
    "            \n",
    "            # 将训练集那个序号的图像的文件path和文件名赋值给X_train_name这个二维dictionary\n",
    "\n",
    "\n",
    "        for split_method_test in test:\n",
    "\n",
    "            # split_method_test的值是每个split方法，其值为图像序号\n",
    "            \n",
    "            X_test_name[chrNo][split_method_number].append(theWhole[chrNo][split_method_test])\n",
    "            \n",
    "            # 同样将测试集的路径和文件名赋值给X_test_name\n",
    "\n",
    "        split_method_number = split_method_number + 1\n",
    "        \n",
    "        # Split分法序号自加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_name['chr_09'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_name['chr_09'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test_name['chr_09'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_name['chr_09'][1] # 表示第一轮split的方法的1号染色体的训练样本的文件名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_name['chr_09'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration Starts Here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Iteration 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Image Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Performance variables defined for iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterationNumber = 0\n",
    "accuracies = {}\n",
    "performanceReport = {}\n",
    "auc_value = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.x Display the Split Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Loops start here ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iterationNumber in range(k):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print('Iteration No. ', iterationNumber)\n",
    "\n",
    "\n",
    "    for chrNo in theWhole.keys():\n",
    "        print(chrNo)\n",
    "        print('   Train: ')\n",
    "        for item in X_train_name[chrNo][iterationNumber]:\n",
    "            print('       ', item.split('\\\\')[-1])\n",
    "        print('   Test: ')\n",
    "        for item in X_test_name[chrNo][iterationNumber]:\n",
    "            print('       ', item.split('\\\\')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Assignment of Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.1 Training: Image Object Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    image = {}\n",
    "\n",
    "    # 定义容纳图片对象的dictionary类型的变量image\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for chrNo in theWhole.keys():\n",
    "        image[chrNo] = []\n",
    "        for case in X_train_name[chrNo][iterationNumber]:\n",
    "\n",
    "            # 上面一行第二个中括号内为split的序号，0为第0次split分法\n",
    "\n",
    "            img = Image.open(case)\n",
    "            image[chrNo].append(img)\n",
    "\n",
    "            # image字典接受的是图片对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    image['chr_09'][1] # 测试一下图像对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.2. Training: Data Extraction from Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Training Set Data: 将图像对象转变为矩阵数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    data = {}\n",
    "    #rgb_data = {}\n",
    "\n",
    "    for chrNo in image.keys():\n",
    "        data[chrNo] = []; \n",
    "        #rgb_data[chrNo] = []\n",
    "        for case in image[chrNo]:\n",
    "            grey, rgb = extractData(case)\n",
    "            data[chrNo].append(grey)\n",
    "            #rgb_data[chrNo].append(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    array = {}\n",
    "\n",
    "    for chrNo in data.keys():\n",
    "        array[chrNo] = []\n",
    "        for case in data[chrNo]:            \n",
    "            array[chrNo].append(case)\n",
    "\n",
    "    x_train_list = []\n",
    "    y_train_list = []\n",
    "\n",
    "    for y, x in array.items():    \n",
    "        for x_item in x:\n",
    "            x_train_list.append(x_item)\n",
    "            y_train_list.append(y)\n",
    "\n",
    "            # 将图像数据赋值给x_train_list;\n",
    "            # 将标签数据赋值给y_train_list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3. Assignment of Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3.1. Testing: Image Object Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 方法同前面的Training Set\n",
    "\n",
    "    image = {}\n",
    "    i = 0\n",
    "\n",
    "    for chrNo in theWhole.keys():\n",
    "        image[chrNo] = []\n",
    "        for case in X_test_name[chrNo][iterationNumber]: # Change here for different iterations!!!!!\n",
    "\n",
    "            # 上面一行第二个中括号内为split的序号，0为第0次split分法\n",
    "\n",
    "            img = Image.open(case)\n",
    "            image[chrNo].append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3.2. Testing: Data Extraction from Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    data = {}\n",
    "    #rgb_data = {}\n",
    "\n",
    "    for chrNo in image.keys():\n",
    "        data[chrNo] = []; \n",
    "        #rgb_data[chrNo] = []\n",
    "        for case in image[chrNo]:\n",
    "            grey, rgb = extractData(case)\n",
    "            data[chrNo].append(grey)\n",
    "            #rgb_data[chrNo].append(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    array = {}\n",
    "\n",
    "    for chrNo in data.keys():\n",
    "        array[chrNo] = []\n",
    "        for case in data[chrNo]:            \n",
    "            array[chrNo].append(case)\n",
    "\n",
    "    x_test_list = []\n",
    "    y_test_list = []\n",
    "\n",
    "    for y, x in array.items():    \n",
    "        for x_item in x:\n",
    "            x_test_list.append(x_item)\n",
    "            y_test_list.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4. ChromConvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 将染色体序号和异常核型名称更换为序号，序号定义在程序开始部分\n",
    "\n",
    "    y_train_digital_list = []\n",
    "    for item in y_train_list:\n",
    "        y_train_digital_list.append(chromConvert[item])\n",
    "\n",
    "    y_test_digital_list = []\n",
    "    for item in y_test_list:\n",
    "        y_test_digital_list.append(chromConvert[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5. Change to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_train = np.array(x_train_list)\n",
    "    y_train = np.array(y_train_digital_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_test = np.array(x_test_list)\n",
    "    y_test = np.array(y_test_digital_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_train = X_train.reshape(-1, 300, 300, 1)\n",
    "    X_test = X_test.reshape(-1, 300, 300, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Training Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.add(Flatten())\n",
    "    model.add(Dense(300, activation='relu'))\n",
    "    model.add(Dense(400, activation='relu'))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(600, activation='relu'))\n",
    "    model.add(Dense(800, activation='relu'))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(400, activation='relu'))\n",
    "    model.add(Dense(300, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4. Tensorboard Initilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %load_ext tensorboard\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5. Compile the modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6. Fitting (拟合)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.fit(X_train, y_train, epochs=100, batch_size=64, verbose=1, \n",
    "              validation_data=(X_test, y_test),\n",
    "              callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.7 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.8. Tensorboard Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    model.save('saved_model/model_Chr_09_cnn_iteration_'+str(iterationNumber))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model_reload = keras.models.load_model('saved_model/model_Chr_09_cnn_iteration_'+str(iterationNumber))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10. Performance Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.1. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    loss, acc = model_reload.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Accuracy: %.3f' % acc)\n",
    "    accuracies[iterationNumber] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    y_predict = model_reload.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # The number 32 means the type number of all chromosome class number inlcuding abnormal ones\n",
    "    y_predict_filtered = []\n",
    "\n",
    "    for sample in y_predict:\n",
    "        maximum = 0\n",
    "        indicator = 0\n",
    "        for i in range(2):\n",
    "            if sample[i] > maximum:\n",
    "                maximum = sample[i]\n",
    "                indicator = i\n",
    "        y_predict_filtered.append(indicator)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    label = ['chr_09', 'chr_9_inversion']\n",
    "\n",
    "    label_convert = []\n",
    "\n",
    "    for i in range(2):\n",
    "        label_convert.append(chromConvert_reverse[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.2. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    performanceReport[iterationNumber] = classification_report(y_test, y_predict_filtered, target_names=label_convert)\n",
    "\n",
    "    # Change here for different iteration!!!!!\n",
    "\n",
    "    print(performanceReport[iterationNumber])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.3. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    cm = np.array(confusion_matrix(y_test, y_predict_filtered, labels=[0, 1]))\n",
    "    confusion = pd.DataFrame(cm, index=label_convert,\n",
    "                            columns=label_convert)\n",
    "    confusion.to_csv('ConfusionMatrix_Chr_09_KaryoType_CNN' + str(iterationNumber) + '.csv')\n",
    "    confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    plt.figure(figsize=(30, 24))\n",
    "    heat_map = sb.heatmap(confusion, annot=True,  # It's a Seaborn function\n",
    "                          cmap='coolwarm', \n",
    "                          xticklabels=confusion.columns, yticklabels=confusion.index, \n",
    "                          linewidths=.5, \n",
    "                          annot_kws={\"size\": 20})\n",
    "    sb.set(font_scale = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fig = heat_map.get_figure()    \n",
    "    fig.savefig('Heatmap_Chr_09_Iteration_' + str(iterationNumber) + '.png', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.4. ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    plt.plot(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    y_predict_1D = y_predict[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fpr , tpr , thresholds = roc_curve(y_test , y_predict_1D)\n",
    "    auc_rf = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    x = y = np.arange(0,1.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    plt.clf()  # Clear the cache\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot(x, y, '--', color='black')\n",
    "    plt.title('ROC curve of inv(9)(p12q13)', fontsize=15, fontname = 'Times New Roman')\n",
    "    plt.xlabel('False Positive Rate', fontsize=10, fontname = 'Times New Roman')\n",
    "    plt.ylabel('True positive Rate', fontsize=10, fontname = 'Times New Roman')\n",
    "    plt.axis('equal')\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.xticks(fontsize=10, fontname = 'Times New Roman')\n",
    "    plt.yticks(fontsize=10, fontname = 'Times New Roman')\n",
    "\n",
    "    plt.savefig('ROC_Curve_Chr_09_' + str(iterationNumber) + '.png', dpi=400)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.10.4.1 AUC Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'auc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6bfe74972aa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mauc_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mauc_value_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miterationNumber\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'auc' is not defined"
     ]
    }
   ],
   "source": [
    "    auc_value = auc(fpr, tpr)\n",
    "    print(auc_value)\n",
    "    auc_value_dict[iterationNumber] = auc_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Loops end here ***"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "KaryoChimneyRock_FullyConnectedNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
